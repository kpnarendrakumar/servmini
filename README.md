ğŸš€ ServMini
ServMini is a powerful CLI tool to transform your Express.js routes into serverless functions (for Vercel, Netlify, or AWS Lambda) â€” with optional AI-powered code reviews using OpenAI, Claude, Ollama, and more.

âœ¨ Features
âœ… Converts routes/\*.js to serverless-ready functions
âœ… Supports .js, .ts, .tsx
âœ… Targets: Vercel, Netlify, AWS Lambda
âœ… Preserves folder structure and relative imports
âœ… Optional AI code reviews using OpenAI, Claude, Ollama, OpenRouter
âœ… Saves AI feedback as .md (optional)
âœ… Auto-detects AI provider based on API key
âœ… CLI-friendly and modular
âœ… Extensible via plugin architecture (upcoming)

ğŸ“¦ Installation
Global (Recommended)
bash
Copy
Edit
npm install -g servmini
From Source (Local Development)
bash
Copy
Edit
git clone https://github.com/kpnarendrakumar/servmini.git
cd servmini
npm install
npm link
Now you can run it globally using:

bash
Copy
Edit
servmini
ğŸš€ Usage
Basic CLI Command
bash
Copy
Edit
servmini <inputDir> [options]
Example (AI Review Enabled)
bash
Copy
Edit
servmini ./backend \
 --target vercel \
 --review \
 --apikey sk-or-xxxxxxxxxxxxxxxx \
 --save-review \
 --out-dir converted
âš™ï¸ CLI Options
Flag Description Default
--target Deployment target: vercel, netlify, aws vercel
--ext Output file extension: js, ts, tsx js
--force-ext Force file extension override
--out-dir Custom output directory converted/
--review Enable AI code review false
--save-review Save AI feedback to .md file false
--provider AI provider: openai, openrouter, claude, ollama, etc. Auto-detect
--apikey API key for AI provider (can also use .env)
--model Model to use (e.g., gpt-4, deepseek/deepseek-r1) Provider default
--prompt Custom prompt for AI reviewer Predefined
--experimental Use experimental transformer engine (convert.js pipeline) (optional) false
--debug Enable verbose logging false

ğŸ§ª Example Express App
js
Copy
Edit
// backend/routes/example.js
import express from 'express';
const router = express.Router();

router.get('/hello', (req, res) => {
res.send('Hello, world!');
});

export default router;
Convert to Vercel Function
bash
Copy
Edit
servmini ./backend --target vercel
ğŸ“ Output Example
--target vercel
markdown
Copy
Edit
converted/
â””â”€â”€ api/
â””â”€â”€ hello.js
--target netlify
Copy
Edit
converted/
â””â”€â”€ hello.js
ğŸ§  AI Review Setup
Supported Providers
Provider Key Prefix Example Model
OpenAI sk- gpt-4, gpt-3.5-turbo
OpenRouter sk-or- deepseek/deepseek-r1, mistral
Claude claude- or anthropic claude-3-opus
Fireworks fw\_ accounts/fireworks/models/llama-v2
Ollama ollama:// ollama://mistral

You can skip AI review by omitting --review.

ğŸ“„ .env Example
Instead of passing keys in CLI:

env
Copy
Edit
AI_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxx
AI_PROVIDER=openrouter
AI_MODEL=deepseek/deepseek-r1-0528:free
ğŸ”§ Developer Mode
Test Locally
bash
Copy
Edit
node ./bin/cli.js ./test --target vercel
Link CLI Globally
bash
Copy
Edit
npm link
servmini ./test --review
ğŸ§¬ Roadmap
Vercel/Netlify/AWS support

AI review with multiple providers

Save .md AI reports

Auto-deploy to Vercel/Netlify

GitHub Action for CI pipelines

Plugin support for custom transformations

GUI version for non-devs

ğŸ™Œ Contributing
bash
Copy
Edit

# Fork the repo and clone locally

git clone https://github.com/kpnarendrakumar/servmini.git

# Create a branch

git checkout -b feature/awesome-feature

# Make changes and commit

git commit -m "âœ¨ Add awesome feature"

# Push and open PR

git push origin feature/awesome-feature
ğŸ“œ License
MIT License Â© 2025 [KP Narendra Kumar]

ğŸŒ Author
KP Narendra Kumar
GitHub: @kpnarendrakumar
Twitter: @narendrakumarkp
